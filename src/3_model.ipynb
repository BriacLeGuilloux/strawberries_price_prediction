{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Series Modeling for Strawberry Price Prediction\n",
    "\n",
    "This notebook implements various time series models using different interpolation methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "from src.fct_feature_eng import *\n",
    "from src.fct_model import *\n",
    "from src.parameter import get_dict_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data = pd.read_csv('data/raw/senior_ds_test.csv')\n",
    "data['start_date'] = pd.to_datetime(data['start_date'])\n",
    "\n",
    "# Split data\n",
    "train_data, test_data = split_train_test(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Process Data with Different Interpolation Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load parameters\n",
    "dict_params = get_dict_params()\n",
    "interpolation_methods = dict_params['interpolation_methods']\n",
    "model_types = dict_params['model_types']\n",
    "\n",
    "processed_data = {}\n",
    "\n",
    "for method in interpolation_methods:\n",
    "    # Process data with current interpolation method\n",
    "    train_processed = preprocessing(train_data, is_training=True, interpolation_method=method)\n",
    "    test_processed = preprocessing(test_data, is_training=False, interpolation_method=method)\n",
    "    \n",
    "    # Create time series of the target\n",
    "    train_ts = train_processed.set_index('start_date')['price']\n",
    "    test_ts = test_processed.set_index('start_date')['price']\n",
    "    \n",
    "    # Check for missing values\n",
    "    if train_ts.isnull().any() or test_ts.isnull().any():\n",
    "        raise ValueError(f\"Missing values detected in {method} processed data\")\n",
    "    \n",
    "    # Save of the results\n",
    "    processed_data[method] = (train_ts, test_ts)\n",
    "    \n",
    "    print(f\"\\nProcessed with {method} interpolation:\")\n",
    "    print(f\"Training set shape: {train_ts.shape}\")\n",
    "    print(f\"Testing set shape: {test_ts.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train and Save Models for Each Interpolation Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_functions = {\n",
    "    'naive': lambda train, test: (naive_forecast(train, test), None),\n",
    "    'arima': fit_arima_model,\n",
    "    'xgboost': fit_xgboost_model\n",
    "}\n",
    "\n",
    "for method in interpolation_methods:\n",
    "    print(f\"\\nTraining models with {method} interpolation:\")\n",
    "    train_ts, test_ts = processed_data[method]\n",
    "    \n",
    "    for model_type in model_types:\n",
    "        fit_func = model_functions[model_type]\n",
    "        pred, model = fit_func(train_ts, test_ts)\n",
    "        save_model_and_predictions(model, pred, f'{model_type}_{method}')\n",
    "    \n",
    "    print(f\"Completed training models with {method} interpolation\")\n",
    "\n",
    "# Save test data for evaluation\n",
    "for method in interpolation_methods:\n",
    "    _, test_ts = processed_data[method]\n",
    "    joblib.dump(test_ts, f'models/test_data_{method}.joblib')\n",
    "\n",
    "print(\"\\nAll models have been trained and saved.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
