{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation for Strawberry Price Prediction\n",
    "\n",
    "This notebook evaluates models trained with different interpolation methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "from src.fct_evaluation import *\n",
    "from src.parameter import get_dict_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Models and Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load parameters\n",
    "dict_params = get_dict_params()\n",
    "interpolation_methods = dict_params['interpolation_methods']\n",
    "model_types = dict_params['model_types']\n",
    "\n",
    "# Load predictions for each interpolation method\n",
    "predictions_by_method = {}\n",
    "test_data_by_method = {}\n",
    "\n",
    "for method in interpolation_methods:\n",
    "    # Load test data\n",
    "    test_data_by_method[method] = joblib.load(f'models/test_data_{method}.joblib')\n",
    "    \n",
    "    # Load predictions\n",
    "    predictions_by_method[method] = {\n",
    "        model_type: joblib.load(f'models/{model_type}_{method}_predictions.joblib')\n",
    "        for model_type in model_types\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Evaluate Models by Interpolation Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_by_method = {}\n",
    "\n",
    "for method in interpolation_methods:\n",
    "    print(f\"\\nEvaluating models with {method} interpolation:\")\n",
    "    \n",
    "    # Get test data and predictions for current method\n",
    "    test_ts = test_data_by_method[method]\n",
    "    predictions = predictions_by_method[method]\n",
    "    \n",
    "    # Plot predictions\n",
    "    plot_predictions(test_ts, predictions, f\"Model Predictions ({method} interpolation)\")\n",
    "    \n",
    "    # Evaluate models\n",
    "    results = evaluate_all_models(test_ts, predictions)\n",
    "    results_by_method[method] = results\n",
    "    \n",
    "    print(\"\\nModel Performance Metrics:\")\n",
    "    print(results['metrics'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Compare Interpolation Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile best models from each method\n",
    "best_models = {}\n",
    "for method in interpolation_methods:\n",
    "    rankings = results_by_method[method]['rankings']\n",
    "    best_model = rankings.index[0]\n",
    "    best_models[method] = {\n",
    "        'model': best_model,\n",
    "        'metrics': results_by_method[method]['metrics'].loc[best_model]\n",
    "    }\n",
    "\n",
    "# Create comparison DataFrame\n",
    "comparison_df = pd.DataFrame({\n",
    "    method: data['metrics']\n",
    "    for method, data in best_models.items()\n",
    "}).T\n",
    "\n",
    "print(\"Best Model Comparison Across Interpolation Methods:\")\n",
    "print(comparison_df)\n",
    "\n",
    "# Plot comparison\n",
    "plt.figure(figsize=(12, 6))\n",
    "comparison_df.plot(kind='bar')\n",
    "plt.title('Best Model Performance by Interpolation Method')\n",
    "plt.xlabel('Interpolation Method')\n",
    "plt.ylabel('Error Metric Value')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(title='Metrics')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Seasonal Analysis of Best Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare seasonal performance of best models\n",
    "best_predictions = {}\n",
    "for method in interpolation_methods:\n",
    "    best_model = best_models[method]['model']\n",
    "    best_predictions[f\"{method}_{best_model}\"] = predictions_by_method[method][best_model]\n",
    "\n",
    "# Use test data from rolling method as reference\n",
    "test_ts = test_data_by_method['rolling']\n",
    "seasonal_performance = analyze_seasonal_performance(test_ts, best_predictions)\n",
    "\n",
    "print(\"\\nSeasonal Performance of Best Models:\")\n",
    "print(seasonal_performance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Conclusions\n",
    "\n",
    "Analysis of different interpolation methods:\n",
    "\n",
    "1. Overall Performance:\n",
    "   - Compare which interpolation method led to better model performance\n",
    "   - Note any consistent patterns across different models\n",
    "\n",
    "2. Seasonal Impact:\n",
    "   - How different interpolation methods handle seasonal patterns\n",
    "   - Which method works better for specific seasons\n",
    "\n",
    "3. Model Specific Findings:\n",
    "   - Which models benefit most from each interpolation method\n",
    "   - Stability of predictions across different methods\n",
    "\n",
    "4. Recommendations:\n",
    "   - Best combination of model and interpolation method\n",
    "   - Trade-offs between different approaches\n",
    "   - Suggestions for further improvements"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
